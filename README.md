# **Portfolio Projects**
**Weekly Activities & Class Participation**:
1. **Exploratory Data Analysis (EDA)**
Description:
The aim was to initially explore datasets to identify basic patterns, trends, or outliers. Typical activities included data profiling, simple visualizations, and understanding fundamental dataset characteristics.
Methodology:
•	Initial data import and profiling
•	Generation of basic visualizations like histograms and bar charts
•	Identification of data distributions and outliers
Tools Used:
AWS Glue DataBrew, Excel, Python (Pandas).
Relevant Uploaded Screenshots/Files:
•[	Initial dataset profiling screenshot ](https://github.com/Ehab-Rakha/data-analyst-ehab/blob/4d581139d09a321c536a41378bf6992dfc6164b2/Initial%20dataset%20profiling%20screenshot%20-%20DataBrew.png)
•	(Visualization, initial profiling or quick insights) [(https://github.com/Ehab-Rakha/data-analyst-ehab/blob/4d581139d09a321c536a41378bf6992dfc6164b2/Visualization%2C%20initial%20profiling%20or%20quick%20insights.png)](https://github.com/Ehab-Rakha/data-analyst-ehab/blob/4d581139d09a321c536a41378bf6992dfc6164b2/Visualization%2C%20initial%20profiling%20or%20quick%20insights.png)
________________________________________
2. **Descriptive Analysis**
**Description**:
Activities involving detailed summary statistics and clear visualization of historical data trends to communicate data insights clearly and concisely.
Methodology:
•	Summarizing data into meaningful metrics
•	Creating summary reports and visual dashboards
•	Comparative analysis between different dataset variables
Tools Used:
AWS Glue DataBrew, Excel.
Relevant Uploaded Screenshots/Files:
•	Screenshot 2025-02-02 174915.png (Data summary/overview, profiling summary)
•	DAP Evaluation.xlsx (Summary statistics & evaluation results)
•	Admissions - SSOT (Curated Zone) - Practice (1).xlsx (Summary and descriptive data)
________________________________________
3. **Diagnostic Analysis**
**Description**:
Focused on determining causes behind observed trends or events. Projects included correlation analysis, examining inter-variable relationships, and deep data inspection to understand 'why' behind outcomes.
Methodology:
•	Correlation and regression analysis
•	Root-cause analysis
•	Comparative and detailed data inspections
Tools Used:
AWS Glue (Data profiling features), Excel.
Relevant Uploaded Screenshots/Files:
•	Screenshot 2025-02-04 172512 (1).png (Correlation heatmap showing variable relationships).
•	Datasets and Settings (1).xlsx (Datasets explicitly used for correlation/diagnostic analysis).
•	Screenshot 2025-02-02 180130.png (Data quality profile with correlation metrics clearly shown)
________________________________________
**Project Parts 1 & 2 (City of Vancouver Project):
4. Data Wrangling (Main Project Part 1)**
**Description**:
Project focused on cleaning, transforming, and preparing data. The emphasis was on handling data ingestion, resolving missing values, data formatting, and preparing for advanced analytics.
Methodology:
•	Data ingestion from raw sources
•	Handling inconsistencies and missing data
•	Transformation, joining, and normalization of datasets
Tools Used:
AWS DataBrew, AWS Glue, Amazon S3, AWS visual ETL.
Relevant Uploaded Screenshots/Files:
•	CC Week #3 - Academics - Ehab.drawio (Detailed data pipeline and ingestion flow).
•	Screenshot 2025-02-04 170734 (2).png (DataBrew recipes and transformations).
•	Poor_Quality_Dataset - Academics - Ehab (1).csv (Dataset explicitly marked as poor quality—ideal wrangling scenario).
________________________________________
**5. Data Quality Control (Main Project Part 2)
Description:**
Dedicated to validating, profiling, and ensuring data integrity, accuracy, and completeness using AWS Glue’s Data Quality features.
Methodology:
•	Establishing validation rules and metrics
•	Profiling for completeness, correctness, and consistency
•	Ensuring datasets conform to defined quality benchmarks
Tools Used:
AWS Glue Data Quality, DataBrew validation rules.
Relevant Uploaded Screenshots/Files:
•	Screenshot 2025-02-04 181604 (1).png (AWS Glue Data Quality validations screenshot).
•	Poor_Quality_Dataset (1).csv (Data explicitly used in data quality control activities).
•	Screenshot 2025-03-10 000142.png (Profiling and validation metrics from Glue Data Quality module).
________________________________________
**AWS ETL Projects (Comprehensive Class Project):
6. Comprehensive Data Engineering & ETL Project
Description:**
Focused on end-to-end implementation using AWS Glue workflows. Includes data ingestion, joining datasets, transformations, and loading the processed data into optimized storage (Parquet files).
Methodology:
•	Data ingestion using AWS Glue Jobs
•	Data transformations, including joins (using visual ETL workflows)
•	Converting datasets into optimized storage formats (Parquet)
Tools Used:
AWS Glue, Amazon S3, Glue Visual ETL.
Relevant Uploaded Screenshots/Files:
•	Screenshot 2025-02-17 205749 (2).png (Glue Visual ETL Workflow showing "Extract Apps" and "Extract Payments" joins).
•	Admissions - Data-Enriching (1).xlsx (Comprehensive data used for join operations).
•	Screenshot 2025-03-09 235946.png (AWS S3 bucket with output files in Parquet format).
________________________________________
**Special Analysis (Learning, Sales & Admissions Data):
7. Specialized Data Analysis and Insights
Description:**
Focused on generating actionable insights for specific business cases (Learning Analytics, Sales Analysis, Admission Data Analysis). This involves descriptive and diagnostic analytics to uncover insights.
Methodology:
•	Focused descriptive summaries
•	Diagnostic analytics to understand key drivers
•	Visualization and actionable recommendations
Tools Used:
Excel, AWS Glue, AWS DataBrew.
Relevant Uploaded Screenshots/Files:
•	Learning - Final.xlsx (Detailed Learning Analytics data with clear insights).
•	Sales-SSOT (SSOT) - Practice (1).xlsx (Detailed Sales analysis)
•	Admissions - SSOT (Curated Zone) - Practice (1).xlsx (Insights and diagnostics of admission analytics).
________________________________________
Diagram Screenshots (draw.io & Architecture):
Include these diagrams explicitly in your GitHub repository and README.md for clear visualization of each project's AWS infrastructure and workflows:
•	Infrastructure and AWS Architecture:
o	CC Week #3 - Academics - Ehab.drawio (General AWS Architecture, S3 bucket setup, EC2 servers)
o	CC Week #2 - Academics - Ehab.drawio (Specific server architecture)
o	CC Week #1.drawio (Infrastructure overview)
•	Data Pipelines & ETL Visualizations:
o	Screenshot 2025-02-17 205749 (2).png (Glue Visual ETL flow with detailed data transforms and joins)
o	Screenshot 2025-02-04 170734 (2).png (DataBrew transformations)
•	Data Quality & Validation:
o	Screenshot 2025-02-04 181604 (1).png (Detailed data quality profiling and validation screenshots)
