# **Portfolio Projects**

**Weekly Activities & Class Participation**:

1. **Exploratory Data Analysis (EDA)**

**Description:**

The aim was to initially explore datasets to identify basic patterns, trends, or outliers. Typical activities included data profiling, simple visualizations, and understanding fundamental dataset characteristics.

Methodology:
•	Initial data import and profiling
•	Generation of basic visualizations like histograms and bar charts
•	Identification of data distributions and outliers

Tools Used:
AWS Glue DataBrew, Excel, Python (Pandas).

**Implementation**:

A) ![Initial dataset profiling - DataBrew](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Initial%20dataset%20profiling%20screenshot%20-%20DataBrew.png)



B)	![Visualization, initial profiling or quick insights](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Visualization%2C%20initial%20profiling%20or%20quick%20insights.png)

________________________________________

2. **Descriptive Analysis**

**Description**:

Activities involving detailed summary statistics and clear visualization of historical data trends to communicate data insights clearly and concisely.

Methodology:

•	Summarizing data into meaningful metrics
•	Creating summary reports and visual dashboards
•	Comparative analysis between different dataset variables

Tools Used:

AWS Glue DataBrew, Excel.

**Implementation**:

A)	![Data summary/overview, profiling summary](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Data%20summary-overview%2C%20profiling%20summary.png)


B) ![Summary and descriptive data](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Summary%20and%20descriptive%20data.png)

________________________________________

3. **Diagnostic Analysis**

**Description**:

Focused on determining causes behind observed trends or events. Projects included correlation analysis, examining inter-variable relationships, and deep data inspection to understand 'why' behind outcomes.

Methodology:

•	Correlation and regression analysis
•	Root-cause analysis
•	Comparative and detailed data inspections

Tools Used:

AWS Glue (Data profiling features), Excel.

**Implementation**:

A)	![Correlation heatmap showing variable relationships](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Correlation%20heatmap%20showing%20variable%20relationships.png)

B)	![Dataset explicitly marked as poor quality—ideal wrangling scenario](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Dataset%20explicitly%20marked%20as%20poor%20quality%E2%80%94ideal%20wrangling%20scenario.png)


C)	![Data quality profile with correlation metrics clearly shown](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Data%20quality%20profile%20with%20correlation%20metrics%20clearly%20shown.png)

________________________________________

**Project Parts 1 & 2 (City of Vancouver Project):**

**4. Data Wrangling (Main Project Part 1)**

**Description**:

Project focused on cleaning, transforming, and preparing data. The emphasis was on handling data ingestion, resolving missing values, data formatting, and preparing for advanced analytics.

Methodology:

•	Data ingestion from raw sources
•	Handling inconsistencies and missing data
•	Transformation, joining, and normalization of datasets

Tools Used:

AWS DataBrew, AWS Glue, Amazon S3, AWS visual ETL.

**Implementation**:

A) ![Detailed data pipeline and ingestion flow](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Detailed%20data%20quality%20profiling%20and%20validation.png)


B)![DataBrew recipes and transformations](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/DataBrew%20transformations.png)


C)	![Dataset explicitly marked as poor quality—ideal wrangling scenario](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Dataset%20explicitly%20marked%20as%20poor%20quality%E2%80%94ideal%20wrangling%20scenario.png)

________________________________________

**5. Data Quality Control (Main Project Part 2)
**
**Description:**

Dedicated to validating, profiling, and ensuring data integrity, accuracy, and completeness using AWS Glue’s Data Quality features.

Methodology:

•	Establishing validation rules and metrics
•	Profiling for completeness, correctness, and consistency
•	Ensuring datasets conform to defined quality benchmarks

Tools Used:

AWS Glue Data Quality, DataBrew validation rules.

**Implementation**:

A)	![AWS Glue Data Quality validations screenshot](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/AWS%20Glue%20Data%20Quality%20validations.png)


B) ![Detailed data quality profiling and validation](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Detailed%20data%20quality%20profiling%20and%20validation.png)


C) ![Profiling and validation metrics from Glue Data Quality module](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Detailed%20data%20quality%20profiling%20and%20validation.png)

________________________________________

**AWS ETL Projects (Comprehensive Class Project):**

**6. Comprehensive Data Engineering & ETL Project**

**Description:**
Focused on end-to-end implementation using AWS Glue workflows. Includes data ingestion, joining datasets, transformations, and loading the processed data into optimized storage (Parquet files).

Methodology:

•	Data ingestion using AWS Glue Jobs
•	Data transformations, including joins (using visual ETL workflows)
•	Converting datasets into optimized storage formats (Parquet)

Tools Used:

AWS Glue, Amazon S3, Glue Visual ETL.

**Implementation**:

A) ![Glue Visual ETL Workflow showing Extract Apps and Extract Payments joins](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Glue%20Visual%20ETL%20Workflow%20showing%20%5BExtract%20Apps%5D%20and%20%5BExtract%20Payments%5D%20joins.png)


B) 	![Comprehensive data used for join operations](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Comprehensive%20data%20used%20for%20join%20operations.png)


C) ![AWS S3 bucket with output files in Parquet format](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/AWS%20S3%20bucket%20with%20output%20files%20in%20Parquet%20format.png)

________________________________________

**Special Analysis (Learning, Sales & Admissions Data):**

**7. Specialized Data Analysis and Insights**

**Description:**

Focused on generating actionable insights for specific business cases (Learning Analytics, Sales Analysis, Admission Data Analysis). This involves descriptive and diagnostic analytics to uncover insights.

Methodology:

•	Focused descriptive summaries
•	Diagnostic analytics to understand key drivers
•	Visualization and actionable recommendations

Tools Used:

Excel, AWS Glue, AWS DataBrew.

**Implementation**:

A)![Detailed Sales analysis](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Detailed%20Sales%20analysis.png)

B) 	![Insights and diagnostics of admission analytics](https://raw.githubusercontent.com/Ehab-Rakha/data-analyst-ehab/main/Insights%20and%20diagnostics%20of%20admission%20analytics.png)
